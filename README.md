# LAM

**Project ID:**  Tl44vh6a

<p align="center">
  <img src="https://github.com/epochlab/LAM/blob/main/sample.png">
</p>

--------------------------------------------------------------------

#### Laplacian Associative Memory (LAM)
Abstract: *An extended attractor network model for graph-based hierarchical computation, generating multiscale representations for communities (clusters) of associative links between memory items, and the scale is regulated by the heterogenous modulation of inhibitory circuits.*

[Original Paper, 2021](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8412329/pdf/pcbi.1009296.pdf)

--------------------------------------------------------------------

#### WORK-IN-PROGRESS

++ Concept<br>
Attractor dynamics of recurrent neural circuits offer a biologically plausiable for hierarchical segmentation.
Relationship between attrator networks and the graph-theoretic processing of knowledge structures.

Graph-based segmentation and abstraction.

- Chunking of items; increasing the no. of items retained in the limited capacity of working memory
- Segmentation of words; learning and comprehension of language
- Temporal abstraction of repeated sequences; accelerates reinforcement learning

++ What is the neurological representation?<br>

++ Build<br>
Datasets<br>
Hopfield RNN

Feature | Notes
------- | -------
Arbitary symmetrical graphs | Generalise the one-dimensional sequential structure of temporal associations of the conventional model - (Hopfield?)
Negative associated weights | Assembly specific inhibition

++ Unknown concepts and observations<br>

++ Questions?<br>